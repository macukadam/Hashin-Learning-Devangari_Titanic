{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import scipy.optimize as opt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "## nn.Module is base class\n",
    "## LogisticRegressionModel is actually same as LinearRegressionModel. Cost function makes all the difference\n",
    "## Naming is just to show what we are doing\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size,output_size):\n",
    "        ##inherit everything from nn.module\n",
    "        super(LogisticRegressionModel,self).__init__()\n",
    "        self.linear=nn.Linear(input_size,output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out=self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0000</th>\n",
       "      <th>pixel_0001</th>\n",
       "      <th>pixel_0002</th>\n",
       "      <th>pixel_0003</th>\n",
       "      <th>pixel_0004</th>\n",
       "      <th>pixel_0005</th>\n",
       "      <th>pixel_0006</th>\n",
       "      <th>pixel_0007</th>\n",
       "      <th>pixel_0008</th>\n",
       "      <th>pixel_0009</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_1015</th>\n",
       "      <th>pixel_1016</th>\n",
       "      <th>pixel_1017</th>\n",
       "      <th>pixel_1018</th>\n",
       "      <th>pixel_1019</th>\n",
       "      <th>pixel_1020</th>\n",
       "      <th>pixel_1021</th>\n",
       "      <th>pixel_1022</th>\n",
       "      <th>pixel_1023</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0000  pixel_0001  pixel_0002  pixel_0003  pixel_0004  pixel_0005  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   pixel_0006  pixel_0007  pixel_0008  pixel_0009    ...      pixel_1015  \\\n",
       "0           0           0           0           0    ...               0   \n",
       "1           0           0           0           0    ...               0   \n",
       "2           0           0           0           0    ...               0   \n",
       "3           0           0           0           0    ...               0   \n",
       "4           0           0           0           0    ...               0   \n",
       "\n",
       "   pixel_1016  pixel_1017  pixel_1018  pixel_1019  pixel_1020  pixel_1021  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   pixel_1022  pixel_1023  character  \n",
       "0           0           0          0  \n",
       "1           0           0          0  \n",
       "2           0           0          0  \n",
       "3           0           0          0  \n",
       "4           0           0          0  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/data.csv')\n",
    "df.iloc[:, -1] = LabelEncoder().fit_transform(df.iloc[:, -1])\n",
    "df = df.astype(np.uint8)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numberOfClasses = 46\n",
    "img_width = 32\n",
    "img_height = 32\n",
    "pixel_lenght=img_width*img_height\n",
    "img_depth = 1\n",
    "\n",
    "## We have 4 feature\n",
    "input_size=pixel_lenght\n",
    "output_size=numberOfClasses\n",
    "#Instantiate model\n",
    "model= LogisticRegressionModel(input_size,output_size)\n",
    "\n",
    "#Instantiate Loss Class\n",
    "##criterion=nn.MSELoss() this is for linear regression\n",
    "#This is for logistic regression\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "# Instantiate Optimizer Class\n",
    "learning_rate=0.005\n",
    "momentum=0.95\n",
    "# Optimizer supports momentum.\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate,momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting data for training and testing purposes\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x=df.iloc[:, :-1].as_matrix()\n",
    "y=df.iloc[:, -1].as_matrix()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "x_train=x_train.astype(np.float32)\n",
    "x_test=x_test.astype(np.float32)\n",
    "y_train=y_train.astype(np.int64)\n",
    "y_test=y_test.astype(np.int64)\n",
    "\n",
    "\n",
    "labels = Variable(torch.from_numpy(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss 236.073120117\n",
      "epoch 20, loss 179.401809692\n",
      "epoch 30, loss 164.358703613\n",
      "epoch 40, loss 133.035400391\n",
      "epoch 50, loss 127.367156982\n"
     ]
    }
   ],
   "source": [
    "# Lets train our model\n",
    "epochs=50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch +=1\n",
    "    #Convert numpy array to torch Variable\n",
    "    inputs = Variable(torch.from_numpy(x_train))\n",
    "    labels = Variable(torch.from_numpy(y_train))\n",
    "    \n",
    "    #Clear gradients w.r.t. parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Forward to get output\n",
    "    outputs=model(inputs)\n",
    "    \n",
    "    #Calculate Loss\n",
    "    loss=criterion(outputs,labels)\n",
    "    \n",
    "    #Getting gradients w.r.t parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    #Updating parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    if(epoch%10==0):\n",
    "        print(\"epoch {}, loss {}\".format(epoch,loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30123188405797102"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model(Variable(torch.from_numpy(x_test))).data.numpy()\n",
    "#multi-class regression: for a given row column with largest value's index represents predicted character \n",
    "#due to lack of time I didnt make the conversion however results look true\n",
    "\n",
    "maxIndexes=predicted.argmax(1)\n",
    "\n",
    "\n",
    "\n",
    "(y_test != maxIndexes).sum()/float(y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-f3e2641200fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxIndexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'len'"
     ]
    }
   ],
   "source": [
    "print(maxIndexes.len);\n",
    "print(y_test.len);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
